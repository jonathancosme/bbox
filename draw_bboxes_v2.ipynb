{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e29bed-34dd-4318-b7a6-fbb00784eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4897271a-d9e9-4fbf-a113-d07d6602c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width=None\n",
    "\n",
    "from config import folder_locs, interest_cols, rando_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c466271-d952-46ca-a697-f67dd230df37",
   "metadata": {},
   "source": [
    "# Instructions:\n",
    "1. Put all your photos in the input_photos folder\n",
    "2. Put the annotation file in the input_csvs folder\n",
    "3. Set the input_csv_filename variable (in the User Input section below) to the name of the annotation file\n",
    "4. Run all the cells (top menu: Run > Run All Cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf13fd5-f22d-4569-950e-3b963416d38b",
   "metadata": {},
   "source": [
    "# User Inputs\n",
    "\n",
    "enter the name of the csv file. \n",
    "\n",
    "if the file is an excel file, please save the file as a csv file by:\n",
    "+ opening the excel file\n",
    "+ selecting File from the menu at the top\n",
    "+ selecting Save As\n",
    "+ selecting CSV UTF-8 from the drop-down menu\n",
    "+ selecting Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9019cb2a-0b54-4061-a5b9-66cc1091c61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_csv_filename = 'groundtruth_with_HeadsTails_v2.csv'\n",
    "photo_file_types = ['.jpg', '.jpeg', '.png']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01cfcc3-2040-4c8c-8b57-6ba7a83ddd3c",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95a1354-14d7-4cc3-bde0-fb8d302886c8",
   "metadata": {},
   "source": [
    "creating the relative filepath for the annoation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9896e11b-90ee-4c37-a235-aadb1899fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input_csvs/groundtruth_with_HeadsTails_v2.csv\n"
     ]
    }
   ],
   "source": [
    "input_csv_filepath = folder_locs['in_files'] + input_csv_filename\n",
    "print(input_csv_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8164bb58-8ac1-4e37-ae4f-6bf234d527c8",
   "metadata": {},
   "source": [
    "loading the annotation file as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18e9210-fc9a-49c5-930a-1db25086f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = pd.read_csv(input_csv_filepath)\n",
    "# csv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22054f23-db2c-4343-9827-9d8e6e1ef62f",
   "metadata": {},
   "source": [
    "getting all the uniuqe labels in the annotation file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b19655-23b7-4bb8-b8ca-488097d55a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Swordfish' 'Swordfish_Head' 'Swordfish_Tail' 'Bigeyetuna'\n",
      " 'Bigeyetuna_Head' 'Bigeyetuna_Tail' 'Mahimahi' 'Mahimahi_Tail'\n",
      " 'Mahimahi_Head' 'Makoshark' 'Yellowfintuna' 'Shortbillspearfish' 'Human'\n",
      " 'Nofish' 'Albacore' 'Wahoo' 'IndoPacificsailfish' 'Stripedmarlin'\n",
      " 'Oilfish' 'Skipjacktuna' 'Shark' 'Opah' 'Sicklepomfret' 'Greatbarracuda'\n",
      " 'Blackmarlin' 'Unknownfish' 'roudiescolar' 'Longsnoutedlancetfish'\n",
      " 'Threshershark' 'Pelagicstingray' 'Bluemarlin' 'Snakemackerel'\n",
      " 'Rainbowrunner' 'Pomfret' 'Molamola' 'Escolar' 'Tuna' 'Emptysnap'\n",
      " 'Floatline' 'Heavysnap' 'linesnap' 'Blueshark' 'Lazyline' 'Emptyhand'\n",
      " 'Heavyhand' 'Floathand' 'DaggerPomfret' 'MarineDebris' 'Loggerhead'\n",
      " 'BlueShark' 'BramaSpp' 'NoFish' 'StripedMarlin'\n",
      " 'LongsnoutedlancetfishGills' 'Squid' 'Marlin' 'Gillsonly' 'Hardfloat'\n",
      " 'BFA' 'Laysan' 'Roughpomfret' 'Bramaspp']\n"
     ]
    }
   ],
   "source": [
    "unique_labels = csv_df[interest_cols['label']].unique()\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cb70ef-96ee-42b1-aca2-20d6330d2095",
   "metadata": {},
   "source": [
    "generating colors for the bounding boxes of the unique labels.  \n",
    "a random seed has been set in the config.py file, under the scripts folder.  \n",
    "this means that the colors generated for a certain annotation file will always be the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a29257e-8cf4-4a84-88f6-5075664b1aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(rando_seed)\n",
    "rando_bgrs = np.random.choice(a=np.arange(start=30, \n",
    "                                          stop=225), \n",
    "                              size=3*len(unique_labels), \n",
    "                              replace=False).reshape(len(unique_labels), 3).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76fa51-b352-4a96-a362-1bfe69cddc37",
   "metadata": {},
   "source": [
    "creating a dictionary with the unique labels as keys, and the bounding box colors as the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b392aee5-957f-4f2f-b84a-e51bac6b47b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Albacore': (197, 115, 86),\n",
      " 'BFA': (213, 31, 82),\n",
      " 'Bigeyetuna': (141, 214, 48),\n",
      " 'Bigeyetuna_Head': (112, 39, 194),\n",
      " 'Bigeyetuna_Tail': (147, 99, 143),\n",
      " 'Blackmarlin': (76, 167, 120),\n",
      " 'BlueShark': (119, 38, 43),\n",
      " 'Bluemarlin': (173, 170, 127),\n",
      " 'Blueshark': (107, 219, 193),\n",
      " 'BramaSpp': (89, 196, 161),\n",
      " 'Bramaspp': (117, 104, 151),\n",
      " 'DaggerPomfret': (79, 110, 64),\n",
      " 'Emptyhand': (73, 186, 33),\n",
      " 'Emptysnap': (55, 53, 176),\n",
      " 'Escolar': (155, 58, 70),\n",
      " 'Floathand': (205, 182, 210),\n",
      " 'Floatline': (172, 111, 138),\n",
      " 'Gillsonly': (87, 190, 217),\n",
      " 'Greatbarracuda': (216, 128, 32),\n",
      " 'Hardfloat': (159, 67, 187),\n",
      " 'Heavyhand': (135, 83, 163),\n",
      " 'Heavysnap': (109, 114, 69),\n",
      " 'Human': (49, 198, 103),\n",
      " 'IndoPacificsailfish': (72, 95, 134),\n",
      " 'Laysan': (179, 160, 181),\n",
      " 'Lazyline': (77, 124, 207),\n",
      " 'Loggerhead': (113, 201, 206),\n",
      " 'Longsnoutedlancetfish': (63, 41, 154),\n",
      " 'LongsnoutedlancetfishGills': (93, 84, 137),\n",
      " 'Mahimahi': (222, 149, 153),\n",
      " 'Mahimahi_Head': (188, 145, 97),\n",
      " 'Mahimahi_Tail': (174, 96, 75),\n",
      " 'Makoshark': (123, 60, 131),\n",
      " 'MarineDebris': (37, 140, 121),\n",
      " 'Marlin': (78, 118, 51),\n",
      " 'Molamola': (144, 94, 74),\n",
      " 'NoFish': (47, 102, 200),\n",
      " 'Nofish': (35, 165, 152),\n",
      " 'Oilfish': (59, 166, 90),\n",
      " 'Opah': (139, 71, 162),\n",
      " 'Pelagicstingray': (191, 34, 62),\n",
      " 'Pomfret': (204, 178, 100),\n",
      " 'Rainbowrunner': (211, 171, 30),\n",
      " 'Roughpomfret': (133, 129, 146),\n",
      " 'Shark': (61, 203, 42),\n",
      " 'Shortbillspearfish': (202, 157, 199),\n",
      " 'Sicklepomfret': (130, 56, 158),\n",
      " 'Skipjacktuna': (81, 195, 68),\n",
      " 'Snakemackerel': (169, 40, 92),\n",
      " 'Squid': (80, 221, 88),\n",
      " 'StripedMarlin': (164, 192, 208),\n",
      " 'Stripedmarlin': (189, 108, 106),\n",
      " 'Swordfish': (168, 46, 185),\n",
      " 'Swordfish_Head': (126, 98, 183),\n",
      " 'Swordfish_Tail': (85, 45, 142),\n",
      " 'Threshershark': (184, 36, 57),\n",
      " 'Tuna': (212, 180, 223),\n",
      " 'Unknownfish': (175, 66, 215),\n",
      " 'Wahoo': (125, 65, 220),\n",
      " 'Yellowfintuna': (148, 105, 54),\n",
      " 'linesnap': (91, 150, 116),\n",
      " 'roudiescolar': (52, 156, 177)}\n"
     ]
    }
   ],
   "source": [
    "label_bgrs = {}\n",
    "for i, a_label in enumerate(unique_labels):\n",
    "    label_bgrs[a_label] = tuple(rando_bgrs[i])\n",
    "pprint.pprint(label_bgrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df35fb9-2eb5-40f6-afbe-f29fd5a4b416",
   "metadata": {},
   "source": [
    "create a function to determine if a filename is a photo image.  \n",
    "uses the extenstions defines in photo_file_types variable under Inputs section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1af6f1fd-177a-4585-a6da-c007714deeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_file_a_photo(a_filename):\n",
    "    is_in_photo = [x in a_filename for x in photo_file_types]\n",
    "    is_in_photo = any(is_in_photo)\n",
    "    if is_in_photo:\n",
    "        return a_filename\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c75094d-b835-47f7-9521-0738e56e1b43",
   "metadata": {},
   "source": [
    "get all the files in the input_photos folder, keep only the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94d551a2-5a65-4522-9a3c-db084111769d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_in_input_photos = os.listdir(folder_locs['in_pics'])\n",
    "files_in_input_photos = [is_file_a_photo(x) for x in files_in_input_photos if is_file_a_photo(x)]\n",
    "len(files_in_input_photos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab4a1b-bf55-4c22-9c45-8c4e304d66f0",
   "metadata": {},
   "source": [
    "get all files in the output_photos folder.  \n",
    "The script will assume that these photos have already been processed, and will not process them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f2e7f0e-520e-49c2-a086-ba8b147fd79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_in_output_photos = os.listdir(folder_locs['out_pics'])\n",
    "file_in_output_photos = [is_file_a_photo(x) for x in file_in_output_photos if is_file_a_photo(x)]\n",
    "len(file_in_output_photos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09d7bc-138f-4784-a2c4-04290726a1f9",
   "metadata": {},
   "source": [
    "create a dataframe for the results of the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e706092-2ca3-4560-b018-518377ae49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['filename', 'result'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e86ca9-f298-46ba-923b-402b6d9e4e27",
   "metadata": {},
   "source": [
    "add notes for files that have already been processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72116f8a-8526-4b2a-882c-264887c753ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['filename'] = file_in_output_photos\n",
    "results_df['result'] = 'already exists in output_photos'\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cab79e-fcd3-454e-a790-8e95068e143d",
   "metadata": {},
   "source": [
    "make a list of the files to process.   \n",
    "This is all the images in the input_photos folder, that does not have a corresponding file in the output_photos folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d19ee16-d481-4079-b9ee-3cc4834a519b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_process = list(set(files_in_input_photos).difference(set(file_in_output_photos)))\n",
    "len(files_to_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afbaa13-235d-47a8-96c2-f9c2249b1ec6",
   "metadata": {},
   "source": [
    "make a list of photos that exists in the csv file, that do NOT exists in the input_photos folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9424fd04-f729-4a36-929c-74ab390874a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123404"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_that_exists = list(set(files_in_input_photos + file_in_output_photos))\n",
    "missing_files = list(set(csv_df[interest_cols['filename']].tolist()).difference(set(files_that_exists)))\n",
    "missing_files = [is_file_a_photo(x) for x in missing_files if is_file_a_photo(x)]\n",
    "len(missing_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ed2b1-f9e7-435b-a706-9ba01a668359",
   "metadata": {},
   "source": [
    "add the missing files to the results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c37501fc-f4d4-44a0-8923-6c750dbb9a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_rows = [{'filename': x, 'result':'missing file in input_photos'} for x in missing_files]\n",
    "results_df = results_df.append(missing_rows, ignore_index=True)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f49bafe",
   "metadata": {},
   "source": [
    "get a list of all files that are not photos in the csv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64881e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_file_not_a_photo(a_filename):\n",
    "    is_not_in_photo = [x in a_filename for x in photo_file_types]\n",
    "    is_not_in_photo = not any(is_not_in_photo)\n",
    "    if is_not_in_photo:\n",
    "        return a_filename\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b159a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_photo_file = csv_df[interest_cols['filename']].tolist()\n",
    "not_photo_file = [is_file_not_a_photo(x) for x in not_photo_file if is_file_not_a_photo(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e4f534",
   "metadata": {},
   "source": [
    "add files that are not photos to results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2c45565",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_photo_rows = [{'filename': x, 'result':'file is not a photo'} for x in not_photo_file]\n",
    "results_df = results_df.append(not_photo_rows, ignore_index=True)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2021a347-9ecc-450a-8d45-0aef74c14339",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_from_csv = list(set(files_to_process).difference(set(csv_df[interest_cols['filename']].tolist())))\n",
    "csv_missing_rows = [{'filename': x, 'result':'photo is not in csv file'} for x in missing_from_csv]\n",
    "results_df = results_df.append(csv_missing_rows, ignore_index=True)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50267e9a-cb72-40ad-bea0-57646865c183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_process_2 = list(set(files_to_process).difference(set(missing_from_csv)))\n",
    "len(files_to_process_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f025482-2ed2-43f4-befb-21a544800177",
   "metadata": {},
   "source": [
    "subset the csv_df to contain only rows that have existing files in the input_photos folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01256002-f85c-4b79-814b-623edd5a424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_df = csv_df.set_index(interest_cols['filename']).loc[files_to_process_2].reset_index()\n",
    "# csv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560d4b1-4e99-4cec-a865-77b5b18091b2",
   "metadata": {},
   "source": [
    "create the function to annotate and save an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbc72b1d-e2c8-47e8-b4b6-ac4caca81d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotated_image(filename):\n",
    "    txt_color=(255, 255, 255) # the text color will be white\n",
    "    cur_df = csv_df[csv_df[interest_cols['filename']]==filename].copy() # subset the dataframe for one photo\n",
    "    cur_filepath = folder_locs['in_pics'] + filename # create the filepath for the filename\n",
    "    cur_img = cv.imread(cur_filepath)\n",
    "    line_thickness = max(round(sum(cur_img.shape) / 2 * 0.003), 2)  # calculate bbox line thickness\n",
    "    n_rows = cur_df.shape[0]\n",
    "    cur_row = 0\n",
    "    try:\n",
    "        for i, row in cur_df.iterrows():\n",
    "\n",
    "            cur_label = row[interest_cols['label']] # get the label of the row\n",
    "\n",
    "            # get the color (BGR) for the label\n",
    "            cur_col = label_bgrs[cur_label]\n",
    "\n",
    "            # make rectangle xy coordinates\n",
    "            x1 = int(row[interest_cols['x1']])\n",
    "            y1 = int(row[interest_cols['y1']])\n",
    "            x2 = int(row[interest_cols['x2']])\n",
    "            y2 = int(row[interest_cols['y2']])\n",
    "            coord_1, coord_2 = (x1, y1), (x2, y2)\n",
    "\n",
    "            # draw the bounding box\n",
    "            cv.rectangle(cur_img, \n",
    "                         coord_1, \n",
    "                         coord_2, \n",
    "                         cur_col, \n",
    "                         thickness=line_thickness, \n",
    "                         lineType=cv.LINE_AA,\n",
    "                        )\n",
    "\n",
    "            # insert text label\n",
    "            font_thickness = max(line_thickness - 1, 1)\n",
    "            w, h = cv.getTextSize(cur_label, \n",
    "                                  0, \n",
    "                                  fontScale=line_thickness / 3, \n",
    "                                  thickness=font_thickness)[0]\n",
    "            coord_2 = coord_1[0] + w, coord_1[1] - h - 3\n",
    "            cv.rectangle(cur_img, \n",
    "                         coord_1, \n",
    "                         coord_2, \n",
    "                         cur_col, \n",
    "                         -1, \n",
    "                         cv.LINE_AA,\n",
    "                        )\n",
    "            cv.putText(cur_img, \n",
    "                       cur_label, \n",
    "                       (coord_1[0], coord_1[1] - 2), \n",
    "                       0, \n",
    "                       line_thickness / 3, \n",
    "                       txt_color, \n",
    "                       thickness=font_thickness, \n",
    "                       lineType=cv.LINE_AA,\n",
    "                      )\n",
    "\n",
    "            cur_row += 1\n",
    "\n",
    "        out_filepath = folder_locs['out_pics'] + filename # create relative filepath of the image to be saved\n",
    "        cv.imwrite(out_filepath, cur_img) # save the file\n",
    "        return {'filename': filename, 'result': 'success'}\n",
    "    \n",
    "    except:\n",
    "        return {'filename': filename, 'result': 'failed'}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ad69bb7-7e72-4fdb-968c-0d271b58c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_map_async_with_results(func,\n",
    "                              obj):\n",
    "    \"\"\"\n",
    "    PARAMS:\n",
    "    + function: func\n",
    "    + list: obj\n",
    "\n",
    "    RETURNS:\n",
    "    + list: res\n",
    "\n",
    "    DESC:\n",
    "    general function for parallel. takes a function, and a list of parameters,\n",
    "    and applies the function to each item in the list.\n",
    "    detects number of cores available, and uses all of them.\n",
    "    parallel application is asynchronous, so it will not execute in list order necessarily.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    n_processors = mp.cpu_count()\n",
    "    n_processors = int(n_processors * 0.75) # use only 75% of available processors\n",
    "    pool = mp.Pool(n_processors)\n",
    "    res = pool.map_async(func,\n",
    "                         obj)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return res.get()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9954d32-ebc7-4a26-8e47-799701417b0d",
   "metadata": {},
   "source": [
    "create a list of filenames to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84c09385-df65-41eb-b764-200e9ee6d172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = csv_df[interest_cols['filename']].unique()\n",
    "# filenames = filenames[-200::]\n",
    "len(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90052131-8c44-412a-a830-245b5b5fa630",
   "metadata": {},
   "source": [
    "process the files in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9799827-6b3c-4b8c-911a-dc0f6c6821bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.07 ms, sys: 58.1 ms, total: 66.2 ms\n",
      "Wall time: 70.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = mp_map_async_with_results(create_annotated_image, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8b260-2e63-41a5-bb29-f03740096b83",
   "metadata": {},
   "source": [
    "iterate through each filename and get the result of the processing (either 'success' of 'failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2b38f4f-b27e-410e-8c7b-25697ac1228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# results = []\n",
    "# for i, filename in enumerate(filenames):\n",
    "#     results.append(create_annotated_image(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0df76f-0fe3-4160-a23a-c7bbb4ab5bd1",
   "metadata": {},
   "source": [
    "add the results of the functions to the results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8d48258-e304-4034-afae-4962ddbe6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.concat([results_df, pd.DataFrame(results)], ignore_index=True)\n",
    "# results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38755b8-0930-4f59-9f41-3adcc01f8b8a",
   "metadata": {},
   "source": [
    "save the results_df as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a2549f7-574e-43a3-8f9f-fc136c656e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(folder_locs['out_res'] + 'results_' + str(time.time()) + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
